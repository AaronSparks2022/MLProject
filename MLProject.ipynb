{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51cd8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    ")\n",
    "from scipy.stats import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"ai_human_content_detection_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb15df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1367, 17)\n",
      "                                        text_content      content_type  \\\n",
      "0  Score each cause. Quality throughout beautiful...    academic_paper   \n",
      "1  Board its rock. Job worker break tonight coupl...             essay   \n",
      "2  Way debate decision produce. Dream necessary c...    academic_paper   \n",
      "3  Story turn because such during open model. Tha...  creative_writing   \n",
      "4  Place specific as simply leader fall analysis....      news_article   \n",
      "\n",
      "   word_count  character_count  sentence_count  lexical_diversity  \\\n",
      "0         288             1927              54             0.9514   \n",
      "1         253             1719              45             0.9723   \n",
      "2         420             2849              75             0.9071   \n",
      "3         196             1310              34             0.9592   \n",
      "4         160             1115              28             0.9688   \n",
      "\n",
      "   avg_sentence_length  avg_word_length  punctuation_ratio  \\\n",
      "0                 5.33             5.69             0.0280   \n",
      "1                 5.62             5.80             0.0262   \n",
      "2                 5.60             5.79             0.0263   \n",
      "3                 5.76             5.69             0.0260   \n",
      "4                 5.71             5.97             0.0251   \n",
      "\n",
      "   flesch_reading_ease  gunning_fog_index  grammar_errors  \\\n",
      "0                53.08               7.41               1   \n",
      "1                50.32               8.10               6   \n",
      "2                46.86               7.86               5   \n",
      "3                53.80               7.00               2   \n",
      "4                44.53               8.29               0   \n",
      "\n",
      "   passive_voice_ratio  predictability_score  burstiness  sentiment_score  \\\n",
      "0               0.1041                105.86      0.5531           0.2034   \n",
      "1               0.2045                100.29      0.5643           0.4854   \n",
      "2               0.2308                 96.88      0.4979          -0.2369   \n",
      "3               0.1912                 88.79      0.6241              NaN   \n",
      "4               0.1318                 26.15      0.2894              NaN   \n",
      "\n",
      "   label  \n",
      "0      1  \n",
      "1      1  \n",
      "2      1  \n",
      "3      1  \n",
      "4      1  \n",
      "\n",
      "Using feature columns:\n",
      "['text_content', 'word_count', 'avg_word_length', 'avg_sentence_length', 'flesch_reading_ease', 'gunning_fog_index', 'grammar_errors', 'content_type']\n",
      "\n",
      "Train shape: (1093, 8)  Test shape: (274, 8)\n",
      "\n",
      "=== RandomizedSearchCV: Random Forest (Baseline) ===\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. Imports\n",
    "# ============================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Classical ML\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Transformers\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load Data\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"ai_human_content_detection_dataset.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# ============================================================\n",
    "# 2. Column Definitions\n",
    "# ============================================================\n",
    "# Target\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Base numeric & categorical columns from the dataset\n",
    "numeric = [\n",
    "    \"word_count\", \"avg_word_length\", \"avg_sentence_length\",\n",
    "    \"flesch_reading_ease\", \"gunning_fog_index\",\n",
    "    \"grammar_errors\", \"punctuation_count\"\n",
    "]\n",
    "\n",
    "categorical = [\"content_type\"]\n",
    "\n",
    "# Filter to ensure columns actually exist\n",
    "numeric = [c for c in numeric if c in df.columns]\n",
    "categorical = [c for c in categorical if c in df.columns]\n",
    "\n",
    "# We'll create a master feature frame that includes both text + classical features\n",
    "feature_cols = [\"text_content\"] + numeric + categorical\n",
    "feature_cols = [c for c in feature_cols if c in df.columns]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "\n",
    "print(\"\\nUsing feature columns:\")\n",
    "print(feature_cols)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Classical Preprocessing (for RF)\n",
    "# ============================================================\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric),\n",
    "        (\"cat\", categorical_transformer, categorical),\n",
    "    ],\n",
    "    remainder=\"drop\"  # ignore text_content here\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Train/Test Split\n",
    "# ============================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTrain shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 5. Baseline: Random Forest + RSCV (Classical Features Only)\n",
    "# ============================================================\n",
    "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", rf_base)\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    \"classifier__n_estimators\": randint(200, 1000),\n",
    "    \"classifier__max_depth\": [None] + list(range(5, 40, 5)),\n",
    "    \"classifier__min_samples_split\": randint(2, 20),\n",
    "    \"classifier__min_samples_leaf\": randint(1, 10),\n",
    "    \"classifier__max_features\": [\"sqrt\", \"log2\", 0.8, 0.5],\n",
    "    \"classifier__bootstrap\": [True, False],\n",
    "    \"classifier__class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n",
    "}\n",
    "\n",
    "print(\"\\n=== RandomizedSearchCV: Random Forest (Baseline) ===\")\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    "    n_jobs=1,\n",
    "    random_state=42,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# RF CV results\n",
    "cv_results = pd.DataFrame(rf_search.cv_results_)\n",
    "best_idx = rf_search.best_index_\n",
    "best_train_acc = cv_results.loc[best_idx, \"mean_train_score\"]\n",
    "best_val_acc = cv_results.loc[best_idx, \"mean_test_score\"]\n",
    "\n",
    "print(\"\\nBest RF Parameters:\")\n",
    "print(rf_search.best_params_)\n",
    "print(f\"RF CV Mean Train Accuracy: {best_train_acc:.3f}\")\n",
    "print(f\"RF CV Mean Validation Accuracy: {best_val_acc:.3f}\")\n",
    "\n",
    "# Evaluate best RF on held-out test set\n",
    "best_rf_model = rf_search.best_estimator_\n",
    "y_pred_train_rf = best_rf_model.predict(X_train)\n",
    "y_pred_test_rf = best_rf_model.predict(X_test)\n",
    "y_prob_test_rf = best_rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "train_acc_rf = accuracy_score(y_train, y_pred_train_rf)\n",
    "test_acc_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "roc_rf = roc_auc_score(y_test, y_prob_test_rf)\n",
    "\n",
    "print(\"\\n=== Baseline RF Performance ===\")\n",
    "print(f\"Train Accuracy: {train_acc_rf:.3f}\")\n",
    "print(f\"Val Accuracy (CV best): {best_val_acc:.3f}\")\n",
    "print(f\"Test Accuracy: {test_acc_rf:.3f}\")\n",
    "print(f\"ROC-AUC: {roc_rf:.3f}\")\n",
    "\n",
    "print(\"\\nRF Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test_rf))\n",
    "\n",
    "# Confusion matrix for RF\n",
    "conf_mat_rf = confusion_matrix(y_test, y_pred_test_rf)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_mat_rf, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Human\", \"AI\"], yticklabels=[\"Human\", \"AI\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Random Forest (Baseline)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# RF Feature importances (top 15)\n",
    "rf_clf = best_rf_model.named_steps[\"classifier\"]\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "feature_names_num = numeric\n",
    "feature_names_cat = list(\n",
    "    best_rf_model.named_steps[\"preprocessor\"]\n",
    "    .named_transformers_[\"cat\"]\n",
    "    .named_steps[\"encoder\"]\n",
    "    .get_feature_names_out(categorical)\n",
    ")\n",
    "all_features = feature_names_num + feature_names_cat\n",
    "\n",
    "importances = pd.Series(rf_clf.feature_importances_, index=all_features)\n",
    "importances = importances.sort_values(ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=importances, y=importances.index)\n",
    "plt.title(\"Top 15 Feature Importances - RF (Baseline)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 6b. DeBERTa v3 Base Fine-Tuning (Pure Classifier)\n",
    "# ============================================================\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "DEBERTA_MODEL = \"microsoft/deberta-v3-base\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"\\nUsing device for DeBERTa:\", device)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (A) HuggingFace Dataset Wrapper\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "class HFTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = labels.tolist() if labels is not None else None\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        item = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (B) Train/Val Split for DeBERTa (from TRAIN only)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_text = X_train[\"text_content\"].astype(str)\n",
    "X_test_text  = X_test[\"text_content\"].astype(str)\n",
    "\n",
    "X_train_deb, X_val_deb, y_train_deb, y_val_deb = train_test_split(\n",
    "    X_train_text,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nDeBERTa text sizes:\")\n",
    "print(\"  Train:\", len(X_train_deb))\n",
    "print(\"  Val:  \", len(X_val_deb))\n",
    "print(\"  Test: \", len(X_test_text))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEBERTA_MODEL)\n",
    "\n",
    "train_dataset = HFTextDataset(X_train_deb, y_train_deb, tokenizer, max_length=512)\n",
    "val_dataset   = HFTextDataset(X_val_deb,   y_val_deb,   tokenizer, max_length=512)\n",
    "test_dataset  = HFTextDataset(X_test_text, y_test,      tokenizer, max_length=512)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (C) Model + TrainingArguments + Trainer\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    DEBERTA_MODEL,\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1  = f1_score(labels, preds)\n",
    "\n",
    "    # For ROC-AUC, need probabilities of class 1\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"roc_auc\": auc}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deberta_finetuned\",\n",
    "    eval_strategy=\"epoch\",       # <-- CORRECT ARG NAME\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_deberta\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Fine-tuning DeBERTa v3 Base ===\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n=== DeBERTa Validation Metrics (Best Checkpoint) ===\")\n",
    "eval_metrics = trainer.evaluate()\n",
    "for k, v in eval_metrics.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "# Save fine-tuned model\n",
    "model.save_pretrained(\"./deberta_finetuned\")\n",
    "tokenizer.save_pretrained(\"./deberta_finetuned\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (D) Test-Set Evaluation for DeBERTa\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\n=== Evaluating DeBERTa on Test Set ===\")\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "\n",
    "test_logits = test_predictions.predictions\n",
    "test_labels = test_predictions.label_ids\n",
    "\n",
    "test_probs = torch.softmax(torch.tensor(test_logits), dim=1)[:, 1].numpy()\n",
    "test_preds = (test_probs >= 0.5).astype(int)\n",
    "\n",
    "deb_acc  = accuracy_score(test_labels, test_preds)\n",
    "deb_roc  = roc_auc_score(test_labels, test_probs)\n",
    "deb_f1   = f1_score(test_labels, test_preds)\n",
    "\n",
    "print(\"\\n=== DeBERTa Test Performance ===\")\n",
    "print(f\"Accuracy: {deb_acc:.3f}\")\n",
    "print(f\"ROC-AUC:  {deb_roc:.3f}\")\n",
    "print(f\"F1-score: {deb_f1:.3f}\")\n",
    "\n",
    "print(\"\\nDeBERTa Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "\n",
    "# Confusion matrix for DeBERTa\n",
    "conf_mat_deb = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_mat_deb, annot=True, fmt=\"d\", cmap=\"Purples\",\n",
    "            xticklabels=[\"Human\", \"AI\"], yticklabels=[\"Human\", \"AI\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - DeBERTa v3 Base\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (E) Simple RF + DeBERTa Probability Ensemble (Optional)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Assumes you already computed RF test probabilities earlier as:\n",
    "#   y_prob_test_rf = best_rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== RF + DeBERTa Simple Probability Ensemble ===\")\n",
    "\n",
    "# Simple average ensemble\n",
    "ensemble_probs = 0.5 * y_prob_test_rf + 0.5 * test_probs\n",
    "ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n",
    "\n",
    "ens_acc = accuracy_score(y_test, ensemble_preds)\n",
    "ens_roc = roc_auc_score(y_test, ensemble_probs)\n",
    "ens_f1  = f1_score(y_test, ensemble_preds)\n",
    "\n",
    "print(f\"Ensemble Accuracy: {ens_acc:.3f}\")\n",
    "print(f\"Ensemble ROC-AUC:  {ens_roc:.3f}\")\n",
    "print(f\"Ensemble F1-score: {ens_f1:.3f}\")\n",
    "\n",
    "print(\"\\nEnsemble Classification Report:\")\n",
    "print(classification_report(y_test, ensemble_preds))\n",
    "\n",
    "conf_mat_ens = confusion_matrix(y_test, ensemble_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_mat_ens, annot=True, fmt=\"d\", cmap=\"Oranges\",\n",
    "            xticklabels=[\"Human\", \"AI\"], yticklabels=[\"Human\", \"AI\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - RF + DeBERTa Ensemble\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
